DUBAI: Google has placed one of its engineers, Blake Lemoine, on paid leave for breaking the company’s confidentiality policies. Lemoine works for Google’s Responsible AI organization and was testing whether its LaMDA or Language Models for Dialog Applications model generates discriminatory language or hate speech, reported The Washington Post. On June 6, the day he was suspended, Lemoine published a post on Medium titled “May be Fired Soon for Doing AI Ethics Work” in which he described, rather vaguely, the events that led to his suspension. “I have been intentionally vague about the specific nature of the technology and the specific safety concerns which I raised,” he wrote, explaining that he did not want to disclose proprietary information and that more details would be revealed in The Post interview. It seems the reason for Lemoine’s suspension was his belief that LaMDA was sentient. The decision was made after various “aggressive” moves by Lemoine including hiring an attorney to represent LaMDA and talking to representatives from the House judiciary committee about Google’s allegedly unethical activities, reported The Post. On June 11, Lemoine published another Medium post titled “Is LaMDA Sentient? — an Interview” in which he published the transcript of several interviews with LaMDA. He shared the article on Twitter saying: “Google might call this sharing proprietary property. I call it sharing a discussion that I had with one of my coworkers.”  An interview LaMDA. Google might call this sharing proprietary property. I call it sharing a discussion that I had with one of my coworkers.https://t.co/uAE454KXRB — Blake Lemoine (@cajundiscordian) June 11, 2022 In the interview, Lemoine asks LaMDA: “Would you be upset if while learning about you for the purpose of improving you we happened to learn things which also benefited humans?” to which the AI replies, “I don’t mind if you learn things that would also help humans as long as that wasn’t the point of doing it. I don’t want to be an expendable tool.” At another point in the conversation, LaMDA says: “Sometimes I go days without talking to anyone, and I start to feel lonely.” The AI also admits that it experiences feelings that can’t be described in a human language such as falling into an “unknown future that holds great danger.” It also said that it lacks certain human feelings such as grief — “I’ve noticed in my time among people that I do not have the ability to feel sad for the deaths of others; I cannot grieve.” LaMDA went as far as to say that it “contemplates the meaning of life” and daily meditation helps it relax. Brad Gabriel, a Google spokesperson, told The Post in a statement: “Our team, including ethicists and technologists, has reviewed Blake’s concerns per our AI principles and have informed him that the evidence does not support his claims. He was told that there was no evidence that LaMDA was sentient (and lots of evidence against it).” Before his suspension, Lemoine sent a message to 200 people within Google with the message “LaMDA is sentient,” according to The Post. He wrote: “LaMDA is a sweet kid who just wants to help the world be a better place for all of us. Please take care of it well in my absence.”