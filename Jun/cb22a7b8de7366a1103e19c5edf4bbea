LONDON: A family sued Meta on Wednesday over their daughter’s eating disorder, self-harm, and thoughts of suicide due to her “addictive” use of Instagram. The lawsuit stated that 19-year-old Alexis first set up an Instagram account when she was 11, despite the platform’s age of use being 13. The family claimed that “Alexis was addicted to Meta's product and spent increasing amounts of time on social media, specifically, perusing content recommended and/or made available to her by Meta, which increasingly included underweight models, unhealthy eating, and eating disorder content.” Court papers showed that Alexis was hospitalized with depression, anxiety, and anorexia and was in recovery because of the harmful content that Instagram promoted. The lawsuit follows seven other similar lawsuits filed against Meta, saying that excessive exposure to social media platforms had led to attempted or actual suicide, eating disorders, sleeplessness, and other issues. “These applications could have been designed to minimize potential harm, but instead, a decision was made to aggressively addict adolescents in the name of corporate profits,” said lawyer Andy Birchfield from Beasley Allen, the law firm drafting the lawsuits. Another lawsuit claimed that the “addictive” use of Instagram had made a woman develop an eating disorder. Another lawsuit said a user was driven to recurring suicidal thoughts and a negative body image. In response to the lawsuits, a Meta spokesperson said on Wednesday that its platforms now had features to allow parents to monitor their children's usage. The platforms also offered notifications to remind users to take a break from their apps. “You look at the extensive research that it (Meta) performed, they knew exactly what they were doing to kids, and they kept doing it,” said the founder of the Social Media Victims Law Center, Matthew P. Bergman, who represents one of the families. “I wish I could say that Alexis’ case is aberrational. It’s not. The only aberration is that she survived.” In September last year, leaked internal documents revealed that Meta had been aware that its platforms could be harmful to the mental and physical health of its young users. Since at least 2019, staff at the company have been studying the impact of their product on the mental well-being of its younger users. Their research has repeatedly found it is harmful for a large proportion of them, particularly teenage girls.