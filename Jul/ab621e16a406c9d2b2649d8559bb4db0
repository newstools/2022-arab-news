LONDON: The UK government revealed on Monday that social media firms will face hefty fines if they fail to curb “state-linked” disinformation, particularly from the Kremlin, as part of its forthcoming Online Safety Bill. According to the UK Department for Digital, Culture, Media and Sport, social media companies will be legally obligated to “proactively” prevent and remove attempts by Russia and other countries to interfere with the UK’s political system. This means that social media firms must tackle material from fake accounts set up by individuals or groups acting on behalf of a foreign state that is designed to influence democratic processes. If they fail to tackle such content, Ofcom, the UK’s communication regulator, will have the power to fine social media firms up to 10 percent of their global annual turnover. “The invasion of Ukraine has yet again shown how readily Russia can and will weaponize social media to spread disinformation and lies about its barbaric actions often targeting the very victims of its aggression,” Culture Secretary Nadine Dorries said. “We cannot allow foreign states or their puppets [to use] the internet to conduct hostile online warfare unimpeded,” she added. “That’s why we are strengthening our new internet safety protections to make sure social media firms identify and root out state-backed disinformation.” The new laws come as part of the UK government’s overhaul of the national security laws that will make foreign interference a criminal offense with a maximum jail sentence of 14 years. As per the new Online Safety Bill, foreign interference will become one of 10 online criminal offenses, alongside child abuse, revenge porn, terrorism, fraud, promotion of people smuggling and sexual exploitation. Security Minister Damian Hinds highlighted: “Online information operations are now a core part of state threats activity. The aim can be variously to spread untruths, confuse, undermine confidence in democracy, or sow division in society.” The Online Safety Bill is expected to become law by the end of the year. Last week, Ofcom found that young people do not report harmful content as much as they encounter it on social media platforms. According to the research, 67 percent of people aged between 13 and 24 had seen potentially harmful content online, but only 17 percent reported it.